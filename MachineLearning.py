# -*- coding: utf-8 -*-
"""Copy of DataVisualisation_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fY-DFlvN4xImIPtgHdCcqEh-QkeDvY6p
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st


@st.cache_data
def load_and_merge_data(data_path='Dataset/'):
#Load the uploaded files
    samsung1 = pd.read_csv(f'{data_path}Samsung 1.csv')
    samsung2 = pd.read_csv(f'{data_path}Samsung 2.csv')
    oppo = pd.read_csv(f'{data_path}Oppo.csv')
    xiaomi = pd.read_csv(f'{data_path}Xiomi.csv')
    oneplus = pd.read_csv(f'{data_path}OnePlus.csv')

#Add Device_ID to each file
    samsung1['Device_ID'] = 'Samsung_1'
    samsung2['Device_ID'] = 'Samsung_2'
    oppo['Device_ID'] = 'Oppo'
    xiaomi['Device_ID'] = 'Xiaomi'
    oneplus['Device_ID'] = 'OnePlus'

#Merge files into a masterfile
    merged = pd.concat([samsung1, samsung2, oppo, xiaomi, oneplus], ignore_index=True)

    #View merged file
    merged.info()
    merged['Device_ID'].value_counts()

    #Save merged Dataset
    merged.to_csv('cleaned_master_battery.csv', index=False)

    return merged

"""
# Initial Data Validation & Preprocessing

"""
@st.cache_data
def clean_and_engineer_features(df_raw):
    df = pd.read_csv('cleaned_master_battery.csv')

    df.info()
    df.head()

    #Convert Timestamp to proper datetime
    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')

    df.head()

    #Check for missing or invalid values
    df.isnull().sum().plot(kind='bar', figsize=(10,4))
    plt.title("Missing Values per Column")
    plt.show()

    #Handle missing entries in numeric columns
    df.interpolate(inplace=True)

    #Handle Duplicates
    df.drop_duplicates(inplace=True)

    #Check numeric columns
    num_cols = ['Battery_Capacity', 'Battery_Percentage', 'CPU_Usage',
                'Battery_Operating_Temperature', 'Battery_Voltage', 'Battery_Current']
    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')

    df.describe()

    """# Feature Engineering"""

    #Create an indicator for when charging starts and stops
    #Convert Plugged_In column to boolean
    df['Plugged_In'] = df['Plugged_In'].astype(str).str.lower().isin(['true', '1', 'yes'])

    #Sort by device and timestamp
    df.sort_values(by=['Device_ID', 'Timestamp'], inplace=True)

    #Calculate charging ouraiton
    df['Time_Diff'] = df.groupby('Device_ID')['Timestamp'].diff().dt.total_seconds().fillna(0)
    df['Charging_Duration'] = df.groupby('Device_ID')['Time_Diff'].cumsum() * df['Plugged_In']

    #Calculate mean for current and temp
    df['Mean_Charging_Current'] = df.groupby('Device_ID')['Battery_Current'].transform('mean')
    df['Mean_Temperature'] = df.groupby('Device_ID')['Battery_Operating_Temperature'].transform('mean')

    #Calculate toatal enerygy consumed (Energy = Voltage × Current × Time)
    df['Total_Energy_Consumed'] = (df['Battery_Voltage'] * df['Battery_Current'] * df['Time_Diff']) / (3600)

    #Approximate the cycle process
    df['Battery_Change'] = df.groupby('Device_ID')['Battery_Percentage'].diff().fillna(0)
    df['Cycle_Progress'] = df.groupby('Device_ID')['Battery_Change'].cumsum().abs() / 100

    #Drop columns taht we wont need anymore (time diff and battery change)
    df.drop(columns=['Time_Diff', 'Battery_Change'], inplace=True)

    #Save this into a new dataset
    df.to_csv('feature_engineered_battery.csv', index=False)

    return df

"""# EDA"""

#Overview of everything again
#df.head()

#df.info()
#df.describe()

def display_charging_duration_chart(df):
#Average charging duration by device
    avg_duration = df.groupby('Device_ID')['Charging_Duration'].mean().sort_values()

    fig, ax = plt.figure(figsize=(8,5))
    avg_duration.plot(kind='bar', color='skyblue')
    plt.title('Average Charging Duration by Device')
    plt.ylabel('Duration (seconds)')
    plt.xlabel('Device')
    plt.close(fig)
    return fig

#Temperature vs Battery Percent
def display_temp_vs_percent_chart(df):

    fig, ax = plt.subplots(figsize=(7, 5))
    plt.figure(figsize=(7,5))
    plt.scatter(df['Battery_Percentage'], df['Battery_Operating_Temperature'], alpha=0.4)
    plt.title('Battery Percentage vs Operating Temperature')
    plt.xlabel('Battery Percentage (%)')
    plt.ylabel('Temperature (°C)')
    plt.close(fig)
    return fig

def display_correlation_heatmap(df):
#View which variables are most related to another
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='Blues', fmt=".2f")
    plt.title('Correlation Matrix of Battery Parameters')
    plt.close(fig)
    return fig

def display_energy_consumed_chart(df):
#View total energy consumed by device
    energy = df.groupby('Device_ID')['Total_Energy_Consumed'].sum().sort_values()

    fig, ax = plt.figure(figsize=(8,5))
    energy.plot(kind='bar', color='lightcoral')
    plt.title('Total Energy Consumed by Device')
    plt.ylabel('Energy (Wh)')
    plt.xlabel('Device')
    plt.close(fig)
    return fig

def display_temperature_distribution(df):
#View temperatire distribution
    fig, ax = plt.figure(figsize=(8,5))
    sns.histplot(df['Battery_Operating_Temperature'], bins=30, kde=True, color='orange')
    plt.title('Distribution of Battery Operating Temperature')
    plt.xlabel('Temperature (°C)')
    plt.ylabel('Frequency')
    plt.close(fig)
    return fig

"""# Building and Testing the ML Model
**Predict remaining battery capacity (%) using features such as:**

*   Charging Duration
*   Mean Charging Current
*   Mean Temperature
* Total Energy Consumed
* Cycle Progress
* (and optionally) Device_ID

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

#Load the Dataset
df = pd.read_csv('feature_engineered_battery.csv')

def train_and_save_model(df):
#Sekect features and target
    X = df[['Charging_Duration', 'Mean_Charging_Current', 'Mean_Temperature',
            'Total_Energy_Consumed', 'Cycle_Progress']]
    y = df['Battery_Percentage']  # replace with Remaining_Capacity later if available

    #Split into Training and Testing Sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42)

    #Train 3 models
    # Linear Regression
    lr = LinearRegression()
    lr.fit(X_train, y_train)

    # Decision Tree
    dt = DecisionTreeRegressor(random_state=42)
    dt.fit(X_train, y_train)

    # Random Forest
    rf = RandomForestRegressor(random_state=42, n_estimators=100)
    rf.fit(X_train, y_train)

    models = {'Random Forest': rf, 'Linear Regression': lr, 'Decision Tree': dt}

    for name, model in models.items():
        y_pred = model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        print(f"{name}:")
        print(f" MAE: {mae:.2f}")
        print(f" RMSE: {rmse:.2f}")
        print(f" R²: {r2:.2f}\n")
    return rf, mae, r2,rmse

"""# Feature Importance"""

# just checking
#rf



def get_feature_importance_df(rf_model, feature_names):
#Extract Feature Importance
#rf.feature_importances_
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': rf_model.feature_importances_
    }).sort_values(by='Importance', ascending=False)

    importance_df['Importance (%)'] = (importance_df['Importance'] * 100).round(2)
    importance_df.reset_index(drop=True, inplace=True)
    print(importance_df)

    fig, ax = plt.figure(figsize=(8,5))
    plt.barh(importance_df['Feature'], importance_df['Importance (%)'], color='steelblue')
    plt.title('Feature Importance (Random Forest Regressor)')
    plt.xlabel('Relative Importance (%)')
    plt.ylabel('Feature')
    plt.gca().invert_yaxis()
    plt.close(fig)

    return importance_df, fig

"""# Running the model
The model was trained on normalised data, where most features (e.g., Charging_Duration, Cycle_Progress) range between 0 and 1 instead of raw values.
This scaling ensures consistent learning across variables with different units.
When making predictions, input values must follow the same range; otherwise, the model interprets them as outliers and produces unrealistic results (such as constant 100% predictions).
For example, a Cycle_Progress value of 0.3 represents 30% of the battery total lifespan rather than 300 charge cycles.
"""
def run_test_predictions(rf_model):
    new_data = pd.DataFrame({
        'Charging_Duration': [0.3], # Fraction of total charging time per session (0 = very short, 1 = longest observed)
        'Mean_Charging_Current': [400],  # Average charging current in milliamperes (mA)
        'Mean_Temperature': [32], # Average battery operating temperature in degrees Celsius (°C)
        'Total_Energy_Consumed': [0.01], # Normalised energy used during the session (in Wh-equivalent scale)
        'Cycle_Progress': [0.5] # Proportion of battery life elapsed (0 = new battery, 1 = end-of-life)
    })

    pred_single = rf_model.predict(new_data)
    #print(f"Predicted Remaining Capacity: {pred[0]:.2f}%")

    test_cases = pd.DataFrame({
        'Charging_Duration': [0.1, 0.5, 0.8, 0.3],
        'Mean_Charging_Current': [350, 600, 750, 400],
        'Mean_Temperature': [29, 32, 34, 33],
        'Total_Energy_Consumed': [0.002, 0.01, 0.05, 0.015],
        'Cycle_Progress': [0.1, 0.4, 0.7, 0.5]
    })

    predictions_multi = rf_model.predict(test_cases)
    test_cases['Predicted_Remaining_Capacity (%)'] = predictions_multi.round(2)
    
    # Return both the single prediction result and the full table
    return pred_single[0], test_cases